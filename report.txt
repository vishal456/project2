Project Report
This project used an implementation of DDPG algorithm. I have used Udacity ddpg-pendulum as base architecture and then made changes to train this new environment.

Learning Algorithm:
	ACTOR:
		Linear(state_size, fc1_units), relu #state_size 33, fc1_units = 128
		BatchNorm1d(fc1_units)
		Linear(fc1_units, fc2_units), relu #fc2_units = 128
		BatchNorm1d(fc2_units)
		Linear(fc2_units, action_size), tanh #action_size = 4

	CRITIC:
		Linear(state_size, fc1_units) #state_size 33, fc1_units = 128
		BatchNorm1d(fc1_units)
		Linear(fc1_units+action_size, fc2_units) #fc2_units = 128 action_size = 4
		Linear(fc2_units, 1)

AGENT
	BUFFER_SIZE = int(1e6)	: replay buffer size
	BATCH_SIZE = 128	: mini batch size
	GAMMA = 0.99		: discount factor
	TAU = 1e-3		: for soft update of target parameters
	LR_ACTOR = 1e-4		: learning rate for actor
	LR_CRITIC = 1e-4	: learning rate for critic
	NUM_UPDATES = 10	: how many times network is updated
	TIME_STEPS = 20		: update network every 20th timestep
	EPSILON = 1		: noise discount

Idea for future work:
Implement other DeepRL Algorithms like PPO, A3C.
